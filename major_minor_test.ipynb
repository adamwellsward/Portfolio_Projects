{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc_utils import *\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_lengths, train_indicies, val_set, val_lengths, val_indicies = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration of using OG_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the object\n",
    "og_dataset = OG_Dataset()\n",
    "\n",
    "# Filter the training set to only contain songs in 'major' keys\n",
    "major_train_df, major_train_lengths = og_dataset.filter_df(train_set, train_lengths, col_to_filter='keys', filter_str='major', split_type='train')\n",
    "\n",
    "# Filter the validation set to only contain songs in 'major' keys\n",
    "major_val_df, major_val_lengths  = og_dataset.filter_df(train_set, train_lengths, col_to_filter='keys', filter_str='major', split_type = 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using these Data subsets (This is basically identical to pomegrante_test_Adam.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_obs(melody_obs: np.ndarray, unique_obs: dict) -> np.ndarray:\n",
    "    # make a smaller array out of the unique observations\n",
    "    possible_obs = list(set(unique_obs.flatten()))\n",
    "\n",
    "    df_melody_obs = pd.Series(melody_obs)\n",
    "    df_melody_obs[~df_melody_obs.isin(possible_obs)] = np.nan\n",
    "\n",
    "    # fill forward first to fill all the holes\n",
    "    df_melody_obs.ffill(inplace=True)\n",
    "\n",
    "    # then fill backward to catch the case where\n",
    "    # the beginning is empty\n",
    "    df_melody_obs.bfill(inplace=True)\n",
    "\n",
    "    return df_melody_obs.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_accuracy(full_pred: np.array, true_states: np.array, num_chords: int=None, num_notes: int=None):\n",
    "    '''\n",
    "    Given the predicted matrix of states, compute the misclassification rate compared with the true_observations.\n",
    "    Could be edited in the future to also compute the accuracy of our predicted note sequence.\n",
    "    '''\n",
    "    # check to make sure these are specified correctly\n",
    "    if num_chords is None:\n",
    "        raise ValueError(\"num_chords must be specified\")\n",
    "    if num_notes is None:\n",
    "        raise ValueError(\"num_notes must be specified\")\n",
    "    \n",
    "    # obtain the actual predicted chords \n",
    "    pred_chords = full_pred[:, num_chords-1]\n",
    "    true_chords = true_states[:len(pred_chords), num_chords-1]\n",
    "\n",
    "    # obtain the accuracy\n",
    "    chord_acc = accuracy_score(true_chords, pred_chords)\n",
    "    \n",
    "    return chord_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_set: pd.DataFrame, train_lengths: pd.Series, num_chords: int=1, num_notes: int=0, subset: bool=False, indices=None, lam: int=None, trans_prior: float=0.1, emissions_prior: float=0.1):\n",
    "    \"\"\" \n",
    "    Takes in the train set and parameters for the state space and returns the trained model, along with all of the dictionaries needed to decode the model as a tuple.\n",
    "\n",
    "    To train on a smaller subset of the full train set, use the subset argument and pass in the indices needed. Uses the load_song_subset function.\n",
    "    \"\"\"\n",
    "    # check if we want to do a subset of the full train set; if so, perform it\n",
    "    if subset:\n",
    "        # check that indices are specified; raise and error if not\n",
    "        if indices is None:\n",
    "            raise ValueError(\"Indices must be specified if subset=True\")\n",
    "        train_set, _ = load_song_subset(train_set, train_lengths, indices)\n",
    "\n",
    "    # obtain the states and observations from the songs\n",
    "    true_states, true_observations = dataframe_to_states(train_set, num_chords, num_notes)\n",
    "    \n",
    "    # create the transition matrices for the model\n",
    "    transition_matrix, emission_probs, unique_states, unique_obs, states_to_index, observation_to_index = states_to_transition(true_states, true_observations, lam, trans_prior, emissions_prior)\n",
    "\n",
    "    # now initialize the model and set the matrices for it\n",
    "    model = hmm.CategoricalHMM(n_components=transition_matrix.shape[0], init_params='')\n",
    "    model.transmat_ = transition_matrix.T\n",
    "    model.emissionprob_ = emission_probs.T\n",
    "\n",
    "    # starting_state = np.zeros(unique_states.shape[1])\n",
    "    # starting_state_index = states_to_index[tuple(starting_state)]\n",
    "\n",
    "    # start_probs = np.zeros(transition_matrix.shape[0])\n",
    "    # start_probs[starting_state_index] = 1\n",
    "    \n",
    "    model.startprob_ = np.ones(transition_matrix.shape[0]) / transition_matrix.shape[0]\n",
    "\n",
    "    # return the model,  the dictionaries\n",
    "    return model, (unique_states, unique_obs, states_to_index, observation_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_states(model: hmm.CategoricalHMM, all_dicts: tuple, observation: np.ndarray, song_lengths: list):\n",
    "    \"\"\"\n",
    "    Uses the model to decode an observation. The all_dicts tuple should contain the model dictionaries returned from fit_model\n",
    "    Returns the predicted states.\n",
    "    \"\"\"\n",
    "    # unpack the tuple to get what we need\n",
    "    unique_states, unique_obs, _, observation_to_index = all_dicts\n",
    "\n",
    "    # perform a forward fill on the observation in case there are any values in it that we have never seen before\n",
    "    observation = ffill_obs(observation, unique_obs)\n",
    "    \n",
    "    # get the indices of the observation\n",
    "    observation_indices = np.array([int(observation_to_index[(o,)]) for o in observation])\n",
    "\n",
    "    # get the predicted state indices\n",
    "    _, pred_indices = model.decode(observation_indices.reshape(-1, 1), lengths=song_lengths)\n",
    "\n",
    "    # use the unique_states dictionary to take the indices to the actual states\n",
    "    pred_states = unique_states[pred_indices, :]\n",
    "\n",
    "    # return the predicted states\n",
    "    return pred_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact(seq, lam):\n",
    "    \"\"\"\n",
    "    Redact a sequence of chords to only contain lam repetitions of any given chord in the sequence. Takes in a one-dimensional sequence and returns the \n",
    "    shortened sequence\n",
    "    \"\"\"\n",
    "    if len(seq.shape) != 1:\n",
    "        raise TypeError(\"array must be 1-dimensional\")\n",
    "\n",
    "    # start building a mask for the sequence: True if we are below lam repetitions, False otherwise\n",
    "    curr_val = seq[0]\n",
    "    length = 1\n",
    "    mask = [True]\n",
    "\n",
    "    # iterate through and create the mask\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i] == curr_val:\n",
    "            if length <= lam - 1:\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "            length += 1\n",
    "        else:\n",
    "            mask.append(True)\n",
    "            curr_val = seq[i]\n",
    "            length = 1\n",
    "\n",
    "    # mask out the values and return\n",
    "    mask = np.array(mask)\n",
    "    return seq[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, all_dicts, val_set: pd.DataFrame, val_lengths: pd.Series, num_chords: int=1, num_notes: int=0, subset: bool=False, indices=None, do_print: bool=True):\n",
    "    if subset:\n",
    "        val_set, val_lengths = load_song_subset(val_set, val_lengths, indices)\n",
    "    \n",
    "    true_states, new_song_obs = dataframe_to_states(val_set, num_chords, num_notes)\n",
    "\n",
    "    # get the predicted states (chop off the first element of the songs because it added a 0)\n",
    "    pred_states = predict_states(model, all_dicts, new_song_obs[1:], val_lengths.values.flatten().tolist())\n",
    "\n",
    "    \n",
    "    # print the results, then return the results and the accuracy\n",
    "    if do_print:\n",
    "        print(\"Pred\\t\\tTrue\")\n",
    "        cumul = np.cumsum(val_lengths.values)\n",
    "        for i in range(len(pred_states)):\n",
    "            if i in set(cumul):\n",
    "                print(\"----- New Song -----\")\n",
    "            print(f\"{pred_states[i]}\\t\\t{true_states[i]}\")\n",
    "\n",
    "    # get the accuracy\n",
    "    accuracy = chord_accuracy(pred_states, true_states, num_chords, num_notes)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    return pred_states, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 1931101/1931101 [02:11<00:00, 14731.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\lambda$ = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 495132/495132 [00:38<00:00, 12817.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11363232430947706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 1931101/1931101 [02:16<00:00, 14139.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\lambda$ = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 495132/495132 [00:34<00:00, 14263.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24434696202224862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 1931101/1931101 [02:13<00:00, 14490.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\lambda$ = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 495132/495132 [00:31<00:00, 15698.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2681163810862558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 1931101/1931101 [01:56<00:00, 16611.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\lambda$ = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 495132/495132 [00:29<00:00, 17000.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2933258201853243\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "num_chords = 1\n",
    "num_notes = 0\n",
    "\n",
    "# run through the lambda values and get the accuracy on the validation set for that lambda value\n",
    "for lam in [None, 4, 3, 2]:\n",
    "    model, all_dicts = fit_model(major_train_df, major_train_lengths, num_chords, num_notes, lam=lam, trans_prior=0, emissions_prior=0)\n",
    "\n",
    "    # get the prediction\n",
    "    print(fr\"$\\lambda$ = {lam}\")\n",
    "    pred_states, acc = get_prediction(model, all_dicts, major_val_df, major_val_lengths, do_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 495132/495132 [00:28<00:00, 17140.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.3368670640009856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get the true states (should be the same no matter what)\n",
    "num_chords = 1\n",
    "num_notes = 0\n",
    "true_states, _ = dataframe_to_states(major_val_df, num_chords, num_notes)\n",
    "\n",
    "# get the accuracy of the all I sequence\n",
    "baseline = accuracy_score(true_states[:, num_chords-1].flatten(), np.ones(len(true_states)))\n",
    "print(\"Baseline Accuracy:\", baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
