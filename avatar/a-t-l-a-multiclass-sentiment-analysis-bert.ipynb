{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">MultiClass Sentiment Analysis using BERT</h1>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited by Adam Ward\n",
    "\n",
    "January 2025\n",
    "\n",
    "Original model training done by Ashish Motwani on Kaggle\n",
    "\n",
    "Link: https://www.kaggle.com/code/ashishmotwani/multiclass-sentiment-analysis-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\">Import Required Libraries</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:04:56.526738Z",
     "iopub.status.busy": "2025-01-28T03:04:56.525858Z",
     "iopub.status.idle": "2025-01-28T03:04:56.532715Z",
     "shell.execute_reply": "2025-01-28T03:04:56.531821Z",
     "shell.execute_reply.started": "2025-01-28T03:04:56.526697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\">Loading Data 📅</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T03:05:07.525538Z",
     "iopub.status.busy": "2025-01-28T03:05:07.524682Z",
     "iopub.status.idle": "2025-01-28T03:05:13.613332Z",
     "shell.execute_reply": "2025-01-28T03:05:13.612446Z",
     "shell.execute_reply.started": "2025-01-28T03:05:07.525502Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Charlie_Corley @Kristine1G @amyklobuchar @Sty...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://t.co/YJNiO0p1JV Flagstar Bank disclose...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rwanda is set to host the headquarters of Unit...</td>\n",
       "      <td>en</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OOPS. I typed her name incorrectly (today’s br...</td>\n",
       "      <td>en</td>\n",
       "      <td>litigious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It sucks for me since I'm focused on the natur...</td>\n",
       "      <td>en</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language      Label\n",
       "0  @Charlie_Corley @Kristine1G @amyklobuchar @Sty...       en  litigious\n",
       "2  https://t.co/YJNiO0p1JV Flagstar Bank disclose...       en  litigious\n",
       "3  Rwanda is set to host the headquarters of Unit...       en   positive\n",
       "4  OOPS. I typed her name incorrectly (today’s br...       en  litigious\n",
       "5  It sucks for me since I'm focused on the natur...       en   negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/sentiment-dataset-with-1-million-tweets/dataset.csv').query('Language == \"en\"').head(250000)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:05:16.197297Z",
     "iopub.status.busy": "2025-01-28T03:05:16.196576Z",
     "iopub.status.idle": "2025-01-28T03:05:16.442184Z",
     "shell.execute_reply": "2025-01-28T03:05:16.441311Z",
     "shell.execute_reply.started": "2025-01-28T03:05:16.197265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Label'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['Label']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **We have four classes in our dataset:**\n",
    "1. > ### **Positive**\n",
    "2. > ### **Negative**\n",
    "3. > ### **Uncertain**\n",
    "4. > ### **Litigious**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\">Cleaning Tweets🧹  </h1></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **We preprocess the tweets and remove all unnecessary links, emojis, symbols.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:05:53.924045Z",
     "iopub.status.busy": "2025-01-28T03:05:53.923143Z",
     "iopub.status.idle": "2025-01-28T03:05:59.289623Z",
     "shell.execute_reply": "2025-01-28T03:05:59.288800Z",
     "shell.execute_reply.started": "2025-01-28T03:05:53.924010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', string) \n",
    "\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#\",\"\", temp)\n",
    "    temp = remove_emoji(temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Perform the Cleaning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:07:02.203079Z",
     "iopub.status.busy": "2025-01-28T03:07:02.202803Z",
     "iopub.status.idle": "2025-01-28T03:07:06.716905Z",
     "shell.execute_reply": "2025-01-28T03:07:06.715878Z",
     "shell.execute_reply.started": "2025-01-28T03:07:02.203054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].map(lambda x : clean_tweet(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\"> Converting Text into Tokens</h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'positive': 0,\n",
    "          'negative': 1,\n",
    "          'uncertainty': 2,\n",
    "          'litigious': 3,\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\"> Creating Dataset </h1></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **Since all the tweets are of different size , we'll zero-pad them to the max length : 512**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:08:09.171295Z",
     "iopub.status.busy": "2025-01-28T03:08:09.170428Z",
     "iopub.status.idle": "2025-01-28T03:08:09.177410Z",
     "shell.execute_reply": "2025-01-28T03:08:09.176473Z",
     "shell.execute_reply.started": "2025-01-28T03:08:09.171257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['Label']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['Text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Create the train-validate-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:08:47.571245Z",
     "iopub.status.busy": "2025-01-28T03:08:47.570583Z",
     "iopub.status.idle": "2025-01-28T03:08:47.645193Z",
     "shell.execute_reply": "2025-01-28T03:08:47.644472Z",
     "shell.execute_reply.started": "2025-01-28T03:08:47.571212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **No. of Training Examples : 200k**\n",
    "> ### **No. of Validation Examples : 25k**\n",
    "> ### **No. of Testing Examples : 25k**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\">Creating Model  </h1></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **We'll use the pretrained *BERT Base Model* and fine tune it to our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:08:52.114016Z",
     "iopub.status.busy": "2025-01-28T03:08:52.113680Z",
     "iopub.status.idle": "2025-01-28T03:08:52.120076Z",
     "shell.execute_reply": "2025-01-28T03:08:52.119212Z",
     "shell.execute_reply.started": "2025-01-28T03:08:52.113990Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, out = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\"> Train and Validation Loop ➿ </h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:08:59.740143Z",
     "iopub.status.busy": "2025-01-28T03:08:59.739131Z",
     "iopub.status.idle": "2025-01-28T03:08:59.753887Z",
     "shell.execute_reply": "2025-01-28T03:08:59.753014Z",
     "shell.execute_reply.started": "2025-01-28T03:08:59.740098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs, save_path='model_iter_{iter_num}.pt', save_interval=10000):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    iteration = 0  # To track the global number of iterations\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            iteration += 1  # Increment the iteration count\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save the model every `save_interval` iterations\n",
    "            if iteration % save_interval == 0:\n",
    "                torch.save(model.state_dict(), save_path.format(iter_num=iteration))\n",
    "                print(f\"Model saved at iteration {iteration}\")\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label.long())\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#5642C5; border-radius: 100px 100px; text-align:center\"> Evaluation Loop☑️ </h1></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad(): \n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Test Accuracy: 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:50:15.709074Z",
     "iopub.status.busy": "2025-01-28T03:50:15.708226Z",
     "iopub.status.idle": "2025-01-28T03:50:15.715266Z",
     "shell.execute_reply": "2025-01-28T03:50:15.714467Z",
     "shell.execute_reply.started": "2025-01-28T03:50:15.709039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model, new_data, model_path, batch_size=2, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "\n",
    "    # Load the pretrained model's weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Prepare the new dataset\n",
    "    new_dataset = Dataset(new_data)\n",
    "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_input in tqdm(new_dataloader):\n",
    "\n",
    "            # load in the data specs\n",
    "            data = data_input[0]\n",
    "            mask = data['attention_mask'].to(device)\n",
    "            input_id = data['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "            # Forward pass to get predictions\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            # Get the predicted labels\n",
    "            predicted_labels = output.argmax(dim=1)\n",
    "\n",
    "            # Store the predictions\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## We now predict the labels for the Avatar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import the data set\n",
    "atla = pd.read_csv('../input/atla-full-data/atla_script.csv')\n",
    "\n",
    "# run the prediction using the last-computed model weights\n",
    "model = BertClassifier()\n",
    "pred = predict(model=model, new_data=atla, model_path='../input/atla-full-data/final_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T03:55:19.616598Z",
     "iopub.status.busy": "2025-01-28T03:55:19.615844Z",
     "iopub.status.idle": "2025-01-28T03:55:19.647016Z",
     "shell.execute_reply": "2025-01-28T03:55:19.646294Z",
     "shell.execute_reply.started": "2025-01-28T03:55:19.616559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# put the predictions into the data set and export for further analysis\n",
    "atla.loc[:, \"Label\"] = pred\n",
    "atla.to_csv(\"atla_with_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2540469,
     "sourceId": 4312966,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6559610,
     "sourceId": 10597909,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30302,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
