{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for Avatar: The Last Airbender Dataset\n",
    "    by Adam Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adamwellsward/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from transformers import BertTokenizer\n",
    "# from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>script</th>\n",
       "      <th>ep_number</th>\n",
       "      <th>Book</th>\n",
       "      <th>total_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13364</th>\n",
       "      <td>Suki</td>\n",
       "      <td>And why did you paint me firebending?</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13365</th>\n",
       "      <td>Sokka</td>\n",
       "      <td>I thought it looked more exciting that way. [M...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>Iroh</td>\n",
       "      <td>[Points at painting.] Hey, my belly's not that...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13367</th>\n",
       "      <td>Toph</td>\n",
       "      <td>Well I think you all look perfect! [They laugh.]</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13368</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aang walks past Appa, petting him briefly, bef...</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Character                                             script  ep_number  \\\n",
       "13364      Suki              And why did you paint me firebending?         21   \n",
       "13365     Sokka  I thought it looked more exciting that way. [M...         21   \n",
       "13366      Iroh  [Points at painting.] Hey, my belly's not that...         21   \n",
       "13367      Toph   Well I think you all look perfect! [They laugh.]         21   \n",
       "13368       NaN  Aang walks past Appa, petting him briefly, bef...         21   \n",
       "\n",
       "       Book  total_number  \n",
       "13364     3            61  \n",
       "13365     3            61  \n",
       "13366     3            61  \n",
       "13367     3            61  \n",
       "13368     3            61  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the data\n",
    "data = pd.read_csv(\"ATLA-episodes-scripts.csv\")\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "# clean the data and put it in the format for the model\n",
    "data['script'] = data['script'].map(lambda x : clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Character', 'Text', 'total_number'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# helper function for finding specific character lines\n",
    "def create_individual_mask(substring, full_string_column):\n",
    "    # Use apply to check each element in the column\n",
    "    return full_string_column.apply(lambda x: bool(re.search(re.escape(substring), x)))\n",
    "\n",
    "# helper function for creating a datafram of only a certain list of characters\n",
    "def create_full_mask(substrings, full_string_column):\n",
    "    # Create a regex pattern from the list of substrings\n",
    "    pattern = '|'.join(re.escape(substring) for substring in substrings)\n",
    "    \n",
    "    # Use apply to check each element in the column\n",
    "    return full_string_column.apply(lambda x: False if re.search(r'\\b(Actor|Actress)\\b', x) else bool(re.search(pattern, x)))\n",
    "\n",
    "# drop nan rows containing descriptions\n",
    "data.dropna(inplace=True)\n",
    "data.drop(columns=[\"Book\", \"ep_number\"], inplace=True)\n",
    "\n",
    "# rename the script column to match the other dataset\n",
    "data.rename(columns={\"script\":\"Text\"}, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sokka' 'Katara' 'Zuko' 'Iroh' 'Aang' 'Aang and Sokka' 'Aang:'\n",
      " 'Gyatso and Katara' 'Young Zuko' 'Azula' 'Toph' 'Young Azula'\n",
      " 'Katara (flashback)' 'Aang and Zuko' 'Young Katara' 'Toph and Sokka'\n",
      " 'Katara and Sokka']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Character', 'Text', 'total_number', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the script with only main characters\n",
    "main_chars = [\"Sokka\", \"Katara\", \"Zuko\", \"Iroh\", \"Aang\", \"Toph\", \"Azula\"]\n",
    "print(data[create_full_mask(main_chars, data[\"Character\"])][\"Character\"].unique())\n",
    "\n",
    "# create the Label column\n",
    "data[\"Label\"] = pd.Series()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'positive': 0,\n",
    "          'negative': 1,\n",
    "          'uncertainty': 2,\n",
    "          'litigious': 3,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['Label']]\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['Text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, new_data, model_path, batch_size=2, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "\n",
    "    # Load the pretrained model's weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Prepare the new dataset\n",
    "    new_dataset = Dataset(new_data)\n",
    "    new_dataloader = DataLoader(new_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_input in tqdm(new_dataloader):\n",
    "            mask = data_input['attention_mask'].to(device)\n",
    "            input_id = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            # Forward pass to get predictions\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            # Get the predicted labels (assuming it's a classification model)\n",
    "            predicted_labels = output.argmax(dim=1)\n",
    "\n",
    "            # Store the predictions\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "    return predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
