{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc_utils import *\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_lengths, _, val_set, val_lengths, _, test_set, test_lengths, _ = load_datasets(return_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "      <th>beat</th>\n",
       "      <th>chord</th>\n",
       "      <th>melody</th>\n",
       "      <th>first_key_in_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>G major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measure  beat  chord  melody first_key_in_song\n",
       "0      0.0   1.0      1      80           G major\n",
       "1      0.0   2.5      1      78           G major\n",
       "2      0.0   3.0      1      77           G major\n",
       "3      0.0   3.5      1      75           G major\n",
       "4      1.0   1.0     22      77           G major"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song_subset(train_set, train_lengths, indices):\n",
    "    \"\"\"\n",
    "    Create a subset of the train\"\"\"\n",
    "    end_positions = np.cumsum(train_lengths)\n",
    "    positions = np.insert(end_positions, 0, np.array([0]))\n",
    "    songs = []\n",
    "    for i in indices:\n",
    "        song = train_set.iloc[positions[i] : positions[i+1]]\n",
    "        songs.append(song)\n",
    "\n",
    "    # return songs and lengths\n",
    "    return pd.concat(songs), train_lengths.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_obs(melody_obs: np.ndarray, unique_obs: dict) -> np.ndarray:\n",
    "    # make a smaller array out of the unique observations\n",
    "    possible_obs = list(set(unique_obs.flatten()))\n",
    "\n",
    "    df_melody_obs = pd.Series(melody_obs)\n",
    "    df_melody_obs[~df_melody_obs.isin(possible_obs)] = np.nan\n",
    "\n",
    "    # fill forward first to fill all the holes\n",
    "    df_melody_obs.ffill(inplace=True)\n",
    "\n",
    "    # then fill backward to catch the case where\n",
    "    # the beginning is empty\n",
    "    df_melody_obs.bfill(inplace=True)\n",
    "\n",
    "    return df_melody_obs.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_accuracy(full_pred: np.array, true_states: np.array, num_chords: int=None, num_notes: int=None):\n",
    "    '''\n",
    "    Given the predicted matrix of states, compute the misclassification rate compared with the true_observations.\n",
    "    Could be edited in the future to also compute the accuracy of our predicted note sequence.\n",
    "    '''\n",
    "    # check to make sure these are specified correctly\n",
    "    if num_chords is None:\n",
    "        raise ValueError(\"num_chords must be specified\")\n",
    "    if num_notes is None:\n",
    "        raise ValueError(\"num_notes must be specified\")\n",
    "    \n",
    "    # obtain the actual predicted chords \n",
    "    pred_chords = full_pred[:, num_chords-1]\n",
    "    true_chords = true_states[:len(pred_chords), num_chords-1]\n",
    "\n",
    "    # obtain the accuracy\n",
    "    chord_acc = accuracy_score(true_chords, pred_chords)\n",
    "    \n",
    "    return chord_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_set: pd.DataFrame, train_lengths: pd.Series, num_chords: int=1, num_notes: int=0, subset: bool=False, indices=None, lam: int=None, trans_prior: float=0.1, emissions_prior: float=0.1):\n",
    "    \"\"\" \n",
    "    Takes in the train set and parameters for the state space and returns the trained model, along with all of the dictionaries needed to decode the model as a tuple.\n",
    "\n",
    "    To train on a smaller subset of the full train set, use the subset argument and pass in the indices needed. Uses the load_song_subset function.\n",
    "    \"\"\"\n",
    "    # check if we want to do a subset of the full train set; if so, perform it\n",
    "    if subset:\n",
    "        # check that indices are specified; raise and error if not\n",
    "        if indices is None:\n",
    "            raise ValueError(\"Indices must be specified if subset=True\")\n",
    "        train_set, _ = load_song_subset(train_set, train_lengths, indices)\n",
    "\n",
    "    # obtain the states and observations from the songs\n",
    "    true_states, true_observations = dataframe_to_states(train_set, num_chords, num_notes)\n",
    "    \n",
    "    # create the transition matrices for the model\n",
    "    transition_matrix, emission_probs, unique_states, unique_obs, states_to_index, observation_to_index = states_to_transition(true_states, true_observations, lam, trans_prior, emissions_prior)\n",
    "\n",
    "    # now initialize the model and set the matrices for it\n",
    "    model = hmm.CategoricalHMM(n_components=transition_matrix.shape[0], init_params='')\n",
    "    model.transmat_ = transition_matrix.T\n",
    "    model.emissionprob_ = emission_probs.T\n",
    "\n",
    "    # starting_state = np.zeros(unique_states.shape[1])\n",
    "    # starting_state_index = states_to_index[tuple(starting_state)]\n",
    "\n",
    "    # start_probs = np.zeros(transition_matrix.shape[0])\n",
    "    # start_probs[starting_state_index] = 1\n",
    "    \n",
    "    model.startprob_ = np.ones(transition_matrix.shape[0]) / transition_matrix.shape[0]\n",
    "\n",
    "    # return the model,  the dictionaries\n",
    "    return model, (unique_states, unique_obs, states_to_index, observation_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_states(model: hmm.CategoricalHMM, all_dicts: tuple, observation: np.ndarray, song_lengths: list):\n",
    "    \"\"\"\n",
    "    Uses the model to decode an observation. The all_dicts tuple should contain the model dictionaries returned from fit_model\n",
    "    Returns the predicted states.\n",
    "    \"\"\"\n",
    "    # unpack the tuple to get what we need\n",
    "    unique_states, unique_obs, _, observation_to_index = all_dicts\n",
    "\n",
    "    # perform a forward fill on the observation in case there are any values in it that we have never seen before\n",
    "    observation = ffill_obs(observation, unique_obs)\n",
    "    \n",
    "    # get the indices of the observation\n",
    "    observation_indices = np.array([int(observation_to_index[(o,)]) for o in observation])\n",
    "\n",
    "    # get the predicted state indices\n",
    "    _, pred_indices = model.decode(observation_indices.reshape(-1, 1), lengths=song_lengths)\n",
    "\n",
    "    # use the unique_states dictionary to take the indices to the actual states\n",
    "    pred_states = unique_states[pred_indices, :]\n",
    "\n",
    "    # return the predicted states\n",
    "    return pred_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact(seq, lam):\n",
    "    \"\"\"\n",
    "    Redact a sequence of chords to only contain lam repetitions of any given chord in the sequence. Takes in a one-dimensional sequence and returns the \n",
    "    shortened sequence\n",
    "    \"\"\"\n",
    "    if len(seq.shape) != 1:\n",
    "        raise TypeError(\"array must be 1-dimensional\")\n",
    "\n",
    "    # start building a mask for the sequence: True if we are below lam repetitions, False otherwise\n",
    "    curr_val = seq[0]\n",
    "    length = 1\n",
    "    mask = [True]\n",
    "\n",
    "    # iterate through and create the mask\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i] == curr_val:\n",
    "            if length <= lam - 1:\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "            length += 1\n",
    "        else:\n",
    "            mask.append(True)\n",
    "            curr_val = seq[i]\n",
    "            length = 1\n",
    "\n",
    "    # mask out the values and return\n",
    "    mask = np.array(mask)\n",
    "    return seq[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, all_dicts, val_set: pd.DataFrame, val_lengths: pd.Series, num_chords: int=1, num_notes: int=0, subset: bool=False, indices=None, do_print: bool=True):\n",
    "    if subset:\n",
    "        val_set, val_lengths = load_song_subset(val_set, val_lengths, indices)\n",
    "    \n",
    "    true_states, new_song_obs = dataframe_to_states(val_set, num_chords, num_notes)\n",
    "\n",
    "    # get the predicted states (chop off the first element of the songs because it added a 0)\n",
    "    pred_states = predict_states(model, all_dicts, new_song_obs[1:], val_lengths.values.flatten().tolist())\n",
    "\n",
    "    \n",
    "    # print the results, then return the results and the accuracy\n",
    "    if do_print:\n",
    "        print(\"Pred\\t\\tTrue\")\n",
    "        cumul = np.cumsum(val_lengths.values)\n",
    "        for i in range(len(pred_states)):\n",
    "            if i in set(cumul):\n",
    "                print(\"----- New Song -----\")\n",
    "            print(f\"{pred_states[i]}\\t\\t{true_states[i]}\")\n",
    "\n",
    "    # get the accuracy\n",
    "    accuracy = chord_accuracy(pred_states, true_states, num_chords, num_notes)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    return pred_states, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in string\n",
    "with open('amazing_grace.txt') as f:\n",
    "    ama_gra = f.read()\n",
    "\n",
    "# preprocess string to abc string\n",
    "ama_gra_abc = dataset_to_abc(ama_gra, 'ama_gra', '001')\n",
    "\n",
    "# preprocess abc to dataframe \n",
    "ag_dataframe = abc_to_dataframe(ama_gra_abc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states:   8%|▊         | 192837/2414976 [00:20<03:52, 9542.40it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_c_and_n, t_prior, e_prior \u001b[38;5;129;01min\u001b[39;00m [((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m50.\u001b[39m, \u001b[38;5;241m2025.\u001b[39m), \n\u001b[1;32m     10\u001b[0m                                       ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m50.\u001b[39m, \u001b[38;5;241m3012.5\u001b[39m), \n\u001b[1;32m     11\u001b[0m                                       ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1037.5\u001b[39m, \u001b[38;5;241m1037.5\u001b[39m),\n\u001b[1;32m     12\u001b[0m                                       ((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m30.\u001b[39m, \u001b[38;5;241m0.\u001b[39m),]:\n\u001b[1;32m     13\u001b[0m     num_chords, num_notes \u001b[38;5;241m=\u001b[39m num_c_and_n\n\u001b[0;32m---> 14\u001b[0m     model, all_dicts \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_notes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memissions_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# get the prediction\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_chords = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_chords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_notes = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_notes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, t_prior = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_prior\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, e_prior = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me_prior\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(train_set, train_lengths, num_chords, num_notes, subset, indices, lam, trans_prior, emissions_prior)\u001b[0m\n\u001b[1;32m     12\u001b[0m     train_set, _ \u001b[38;5;241m=\u001b[39m load_song_subset(train_set, train_lengths, indices)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# obtain the states and observations from the songs\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m true_states, true_observations \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_chords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_notes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# create the transition matrices for the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m transition_matrix, emission_probs, unique_states, unique_obs, states_to_index, observation_to_index \u001b[38;5;241m=\u001b[39m states_to_transition(true_states, true_observations, lam, trans_prior, emissions_prior)\n",
      "File \u001b[0;32m~/Documents/acme_labs/auto-harmonizer/abc_utils.py:195\u001b[0m, in \u001b[0;36mdataframe_to_states\u001b[0;34m(song_df, chords_per_state, melody_per_state)\u001b[0m\n\u001b[1;32m    192\u001b[0m         melody_states[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m melody_states[i, \u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# Shift left\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         melody_states[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmelody\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Append new melody\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     observations[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmelody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Don't include the current melody note (melody_states[:, :-1]))\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack([chord_states, melody_states[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]), observations\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:1000\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    999\u001b[0m key_is_scalar \u001b[38;5;241m=\u001b[39m is_scalar(key)\n\u001b[0;32m-> 1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1001\u001b[0m     key \u001b[38;5;241m=\u001b[39m unpack_1tuple(key)\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# num_chords = 1\n",
    "# num_notes = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run through the lambda values and get the accuracy on the validation set for that lambda value\n",
    "for num_c_and_n, t_prior, e_prior in [((1, 0), 50., 2025.), \n",
    "                                      ((1, 0), 50., 3012.5), \n",
    "                                      ((1, 0), 1037.5, 1037.5),\n",
    "                                      ((1, 0), 30., 0.),]:\n",
    "    num_chords, num_notes = num_c_and_n\n",
    "    model, all_dicts = fit_model(train_set, train_lengths, num_chords, num_notes, trans_prior=t_prior, emissions_prior=e_prior)\n",
    "\n",
    "    # get the prediction\n",
    "    print(fr\"n_chords = {num_chords}, n_notes = {num_notes}, t_prior = {t_prior}, e_prior = {e_prior}\")\n",
    "    pred_states, acc = get_prediction(model, all_dicts, ag_dataframe, pd.Series([len(ag_dataframe)]), do_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 36/36 [00:00<00:00, 4421.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3611111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]]),\n",
       " 0.3611111111111111)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing states: 100%|██████████| 604399/604399 [00:18<00:00, 33542.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.3456833223031105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get the true states (should be the same no matter what)\n",
    "num_chords = 1\n",
    "num_notes = 0\n",
    "true_states, _ = dataframe_to_states(val_set, num_chords, num_notes)\n",
    "\n",
    "# get the accuracy of the all I sequence\n",
    "baseline = accuracy_score(true_states[:, num_chords-1].flatten(), np.ones(len(true_states)))\n",
    "print(\"Baseline Accuracy:\", baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acme",
   "language": "python",
   "name": "acme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
